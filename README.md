# ğŸ” Real-Time Fraud Detection Pipeline

A comprehensive fraud detection system built with modern streaming technologies, featuring real-time transaction processing and monitoring dashboards.

## ğŸ“‹ Overview

This project implements an end-to-end fraud detection pipeline using the IEEE CIS Fraud Detection dataset. The system simulates real-time transaction processing through Apache Kafka, applies machine learning models for fraud detection, and provides real-time monitoring through Grafana dashboards.

## ğŸ—ï¸ Architecture

```
IEEE CIS Dataset â†’ Kafka Producer â†’ Kafka Topics â†’ ML Consumer â†’ Redis Cache
                                                                      â†“
                  PostgreSQL â† Fraud Predictions â† ML Model â† Feature Processing
                      â†“
                Grafana Dashboard (Monitoring & Analytics)
```

## ğŸš€ Features

- **Real-time Stream Processing**: Kafka-based event streaming architecture
- **Machine Learning Integration**: Fraud detection using supervised learning models
- **Caching Layer**: Redis for fast feature lookups and session management
- **Persistent Storage**: PostgreSQL for transaction history and predictions
- **Real-time Monitoring**: Grafana dashboards with key metrics and alerts
- **Scalable Design**: Modular architecture supporting horizontal scaling

## ğŸ› ï¸ Tech Stack

- **Stream Processing**: Apache Kafka, Kafka Connect
- **Machine Learning**: Python, XGBoost, Scikit-learn, Pandas, NumPy
- **Caching**: Redis (for feature store and session management)
- **Database**: PostgreSQL (transaction history and predictions)
- **Monitoring**: Grafana (real-time dashboards and alerting)
- **Containerization**: Docker & Docker Compose (fully containerized deployment)
- **Language**: Python 3.8+

## ğŸ“¦ Installation & Setup

### Prerequisites

- Docker & Docker Compose (that's it!)
- Git

**Note**: Python environment is containerized - no local Python setup required!

### Quick Start

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/fraud-detection-pipeline.git
cd fraud-detection-pipeline
```

2. **Start the entire pipeline with Docker**
```bash
# Build and start all services
docker-compose up --build

# Or run in detached mode
docker-compose up -d --build
```

3. **Access the services**
```bash
# Grafana Dashboard: http://localhost:3000 (admin/admin)
# Kafka UI (optional): http://localhost:8080
# Check logs: docker-compose logs -f
```

4. **Stop the pipeline**
```bash
docker-compose down
```

### Alternative: Manual Setup (Development)

If you want to run components individually for development:

```bash
# Set up Python environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt

# Start only infrastructure with Docker
docker-compose up -d kafka redis postgres grafana

# Run Python services manually
python transaction_producer.py
python fraud_detector.py  # In another terminal
```

## ğŸ“Š Dataset

Using the [IEEE-CIS Fraud Detection Dataset](https://www.kaggle.com/c/ieee-fraud-detection) from Kaggle:
- **Training Set**: ~590K transactions
- **Features**: 434 features including transaction amount, product code, card info, etc.
- **Target**: Binary fraud classification

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file in the root directory:

```env
# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC=transactions

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379

# PostgreSQL Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=fraud_detection
POSTGRES_USER=your_user
POSTGRES_PASSWORD=your_password

# ML Model Configuration
MODEL_PATH=models/fraud_model.pkl
THRESHOLD=0.5
```

### Kafka Topics

```bash
# Create required topics
kafka-topics --create --topic transactions --bootstrap-server localhost:9092
kafka-topics --create --topic predictions --bootstrap-server localhost:9092
```

## ğŸ“ˆ Monitoring & Metrics

The Grafana dashboard provides real-time insights:

- **Transaction Volume**: Transactions per second/minute
- **Fraud Detection Rate**: Percentage of flagged transactions
- **System Health**: Kafka consumer lag, processing latency
- **Model Performance**: Prediction confidence distribution
- **Alert Thresholds**: Configurable alerts for anomalies

**Dashboard Access**: http://localhost:3000 (admin/admin)

## ğŸ”¬ Machine Learning

### Model Details
- **Algorithm**: Random Forest Classifier (configurable)
- **Features**: Engineered from transaction data
- **Training**: Offline training on historical data
- **Inference**: Real-time prediction on streaming data

### Feature Engineering
- Transaction amount normalization
- Time-based features (hour, day, etc.)
- User behavior patterns
- Geographic features
- Card usage patterns

### Model Performance
```
AUC-ROC: 96.6% average across folds
Precision: 82% (minimizing false positives)
Recall: 72% (catching actual fraud cases)
F1-Score: 74% (balanced performance)
```

## ğŸ“ Project Structure

```
fraud-detection-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer.py          # Kafka producer for transaction simulation
â”‚   â”œâ”€â”€ consumer.py          # ML consumer for fraud detection
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ fraud_detector.py # ML model implementation
â”‚   â”‚   â””â”€â”€ feature_engineer.py # Feature engineering pipeline
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ kafka_utils.py   # Kafka helper functions
â”‚   â”‚   â”œâ”€â”€ redis_utils.py   # Redis connection utilities
â”‚   â”‚   â””â”€â”€ db_utils.py      # Database utilities
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ settings.py      # Configuration management
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw IEEE CIS dataset
â”‚   â”œâ”€â”€ processed/           # Processed feature data
â”‚   â””â”€â”€ models/              # Trained ML models
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â””â”€â”€ dashboards/      # Grafana dashboard configs
â”‚   â””â”€â”€ prometheus/          # Prometheus configuration (optional)
â”œâ”€â”€ docker-compose.yml       # Infrastructure setup
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Dockerfile              # Application containerization
â””â”€â”€ README.md
```

## ğŸš€ Performance

### Current Throughput
- **Transactions/sec**: ~1,000 (simulated)
- **Processing Latency**: <100ms average
- **Memory Usage**: ~512MB (Python consumer)
- **Storage**: PostgreSQL handles 1M+ records efficiently

### Scaling Considerations
- Kafka partitioning for horizontal scaling
- Redis clustering for cache scaling
- PostgreSQL read replicas for query performance
- Kubernetes deployment ready

## ğŸ”„ Future Improvements

- [ ] **Advanced ML Models**: Experiment with deep learning approaches
- [ ] **Real-time Model Updates**: Online learning capabilities
- [ ] **Feature Store**: Centralized feature management
- [ ] **A/B Testing**: Framework for model experimentation
- [ ] **Advanced Monitoring**: Custom metrics and alerting
- [ ] **Data Validation**: Schema validation and data quality checks
- [ ] **Security**: Authentication and encryption layers
- [ ] **Auto-scaling**: Kubernetes-based auto-scaling

## âš ï¸ Known Limitations

- **Simulated Data**: Uses replay of static dataset, not live transaction feeds
- **Single Node**: Current setup runs on single machine (not distributed)
- **Model Staleness**: No automatic model retraining pipeline
- **Limited Security**: Basic setup without production security measures
- **Data Volume**: Scaled down for demo purposes

## ğŸ¤ Contributing

Interested in contributing? Great! Here are some areas where help is needed:

1. **Model Improvements**: Better algorithms, feature engineering
2. **Scalability**: Distributed processing improvements
3. **Monitoring**: Additional metrics and dashboards
4. **Documentation**: Code documentation and tutorials
5. **Testing**: Unit tests and integration tests

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Contact

**Hari**
- LinkedIn: [https://www.linkedin.com/in/haricharan-b-75037b249/]
- Email: haricharan006@gmail.com
- GitHub: [@hariiiiiiiii/](https://github.com/hariiiiiiiii/)

---

â­ **Found this project helpful?** Give it a star and feel free to fork it!

**Questions or suggestions?** Open an issue or reach out - I'm always excited to discuss fraud detection, streaming architectures, or data engineering approaches!
